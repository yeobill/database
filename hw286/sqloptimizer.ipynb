{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Optimizer in SQL\n",
    "This notebook accompanies the extra [homework assignment](README.md) for CS286A, Fall 2017. Please see that document for instructions on installation and setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load support for the %sql magic in Jupyter, and log into the database.\n",
    "You will have to do this every time you start the kernel in this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgresql://vagrant:vagrant@:5432/optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup 1. Create metadata tables for our optimizer\n",
    "This section sets up all the information needed for our optimizer as a set of metadata tables. You can see a [diagram of the full schema here.](img/metaschema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a separate schema to hold the optimizer's tables and views\n",
    "SQL schemas are like filesystem directories, except they cannot be nested. Here we will separate out the optimizer tables and views by creasing a new schema, `sqlopt`, and setting the database `search_path` to default to `sqlopt`. All the tables and views we define below will be under that schema. By default, in postgresql the search path starts with `public`. So if you connect to this database from psql you will have to reference the optimizer tables with the prefix `sqlopt.`, as in `SELECT * FROM sqlopt.catalog_tables`. More info on schemas is in the [PostgreSQL documentation](https://www.postgresql.org/docs/current/static/ddl-schemas.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP SCHEMA IF EXISTS sqlopt CASCADE;\n",
    "CREATE SCHEMA sqlopt;\n",
    "SET search_path to sqlopt,public;\n",
    "\n",
    "-- Postgres doesn't include a built-in array sorting function.\n",
    "-- We define one here. You do not need to understand this in any detail.\n",
    "CREATE OR REPLACE FUNCTION array_sort(anyarray)\n",
    "RETURNS anyarray AS $$\n",
    "  SELECT ARRAY(SELECT unnest($1) ORDER BY 1)\n",
    "$$ LANGUAGE sql;\n",
    "\n",
    "-- Test the sorting function\n",
    "CREATE TABLE test_array(rownumber integer, words text[]);\n",
    "INSERT INTO test_array VALUES (1, '{the, quick, brown}'), (2, '{four, score, and, seven}');\n",
    "SELECT rownumber, array_sort(words) AS sorted FROM test_array;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System: metadata about the hardware and software configuration\n",
    "The only state we'll keep about our \"hardware configuration\" is the size of the buffer, the number of buffers available for our query operators (sorts, hash joins, etc.) and \"CPU factor\" in the Selinger cost model. For our software configuration, we'll keep the type of our join methods. \n",
    "\n",
    "System information tables have the prefix `system_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS system_hardware CASCADE;\n",
    "DROP TABLE IF EXISTS system_join_methods CASCADE;\n",
    "\n",
    "--\n",
    "-- Machine Config\n",
    "--\n",
    "-- bufpool is size of the buffer pool\n",
    "-- qbufs is the number of pages of memory allocated to each operator\n",
    "-- cpufactor is the constant from Selinger's paper\n",
    "CREATE TABLE system_hardware(bufpool integer, qbufs integer, cpufactor float);\n",
    "INSERT INTO system_hardware VALUES (10, 5, .001);\n",
    "\n",
    "--\n",
    "-- Query Operators\n",
    "--\n",
    "-- right_index_requirement is TRUE if the join algorithm requires the\n",
    "-- join predicate to match an index.\n",
    "CREATE TABLE system_join_methods(name text PRIMARY KEY, right_index_requirement bool);\n",
    "INSERT INTO system_join_methods VALUES \n",
    "  ('BNLJ', false), \n",
    "  ('INLJ', true), \n",
    "  ('Hash', false), \n",
    "  ('Merge', false);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catalog metadata: tables that store information about tables.\n",
    "We'll need to keep track of the user's schema and basic statistics about their data. For this implementation, we'll just use the simple Selinger statistics.\n",
    "\n",
    "All of our catalog tables with start with the prefix `catalog_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS catalog_tables CASCADE;\n",
    "DROP TABLE IF EXISTS catalog_columns CASCADE;\n",
    "DROP TABLE IF EXISTS catalog_access_methods CASCADE;\n",
    "\n",
    "-- tables and columns\n",
    "CREATE TABLE catalog_tables(table_name text PRIMARY KEY, ntups integer, npages integer);\n",
    "CREATE TABLE catalog_columns(table_name text, column_id integer, name text, type text, num_vals integer,\n",
    "                        lo integer, hi integer,\n",
    "                        PRIMARY KEY (table_name, column_id),\n",
    "                        FOREIGN KEY (table_name) REFERENCES catalog_tables);\n",
    "\n",
    "-- access methods: current limitation: single-column search keys\n",
    "CREATE TABLE catalog_access_methods(am_id integer, table_name text, \n",
    "                            column_id integer, type text,\n",
    "                            PRIMARY KEY (am_id),\n",
    "                            FOREIGN KEY (table_name, column_id) \n",
    "                            REFERENCES catalog_columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser metadata: information about the query to be optimized.\n",
    "Here we define tables that hold information about the query to be optimized. You should assume these tables are populated by a parser for SQL; for testing we'll populate them by hand.\n",
    "\n",
    "We only handle simple single-query blocks of the form\n",
    "```SQL\n",
    "   SELECT *\n",
    "     FROM <query_tables>\n",
    "    WHERE <T1.col> <op> <constant> (selections)\n",
    "      AND <T1.col> = <T2.col> (two-relation equijoins)\n",
    "```\n",
    "All the query-specific state has the `query_` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS query_tables CASCADE;\n",
    "DROP TABLE IF EXISTS query_predicates CASCADE;\n",
    "\n",
    "-- tables referenced\n",
    "CREATE TABLE query_tables(table_name text PRIMARY KEY,\n",
    "                          FOREIGN KEY (table_name) REFERENCES catalog_tables);\n",
    "\n",
    "-- Assuming the WHERE clause is in CNF, each of the conjuncts\n",
    "-- is called a \"predicate\" (Selinger calls it a \"Boolean Factor\").\n",
    "-- We currently do not handle OR or NOT predicates, only conjunctions of single-table\n",
    "-- and two-table predicates.\n",
    "-- Note the CHECK constraint that ensures each row holds either single-table or \n",
    "-- two-table information.\n",
    "CREATE TABLE query_predicates(\n",
    "    pred_id integer PRIMARY KEY, \n",
    "    table_left text NOT NULL, column_left integer NOT NULL,\n",
    "    operator char(2), constant integer,        -- for selection predicates\n",
    "    table_right text, column_right integer, -- for join predicates\n",
    "    FOREIGN KEY (table_left, column_left) REFERENCES catalog_columns,\n",
    "    FOREIGN KEY (table_right, column_right) REFERENCES catalog_columns,\n",
    "    FOREIGN KEY (table_left) REFERENCES query_tables,\n",
    "    FOREIGN KEY (table_right) REFERENCES query_tables,\n",
    "    \n",
    "    CHECK ((constant IS NULL AND operator IS NULL AND table_right IS NOT NULL AND column_right IS NOT NULL) \n",
    "           OR \n",
    "           (constant IS NOT NULL AND operator IS NOT NULL AND table_right IS NULL AND column_right IS NULL))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The output of the optimization algorithm.\n",
    "Here we register the schema of the output you need to generate from the Selinger algorithm. You should understand the structure of this table and its constraints well before you try to implement the optimizer algorithm.  This is a typical relational representation of a binary tree, in which each row represents a node in the tree with a unique `node_id`, and references other nodes. Here we're linked upward and downward: we have references to a `lhs` (left-hand-side) child, an `rhs` child, and a `parent` in each node. We also have explicit ordering among siblings captured in `sibling_id`, and a \"level\" of the node within the tree (leaves are at level 1, and parents are 1 level higher than their highest child.)\n",
    "\n",
    "Metadata for the optimizer algorithms is prefixed with `opt_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "--\n",
    "-- Optimizer state\n",
    "--\n",
    "DROP TABLE IF EXISTS opt_chosen_plan;\n",
    "\n",
    "-- The final chosen plan: your code needs to populate this table correctly.\n",
    "CREATE TABLE opt_chosen_plan \n",
    "(\n",
    "    node_id integer PRIMARY KEY,         -- id of this node\n",
    "    level integer,       -- level in the tree (scan is 1)\n",
    "    tables text[],       -- array of tables in this subtree\n",
    "    am_id integer,       -- level=1: access method ID\n",
    "    type text,           -- level=1: access method type\n",
    "    top_join text,       -- level>1: join method\n",
    "    lhs integer,         -- level>1: pid of left child\n",
    "    rhs integer,         -- level>1: pid of right child,\n",
    "    cost float,          -- cost\n",
    "    npages integer,      -- number of pages of output\n",
    "    ntups integer,       -- number of tuples of output\n",
    "    order_table text, \n",
    "    order_column integer,  -- this column and the preceding define the ordering key of the output\n",
    "    parent integer,      -- pid of the parent node\n",
    "    sibling_id integer,  -- position in order of children of this parent (1 = left, 2 = right),\n",
    "    FOREIGN KEY (am_id) REFERENCES catalog_access_methods,\n",
    "    FOREIGN KEY (top_join) REFERENCES system_join_methods,\n",
    "    FOREIGN KEY (lhs) REFERENCES opt_chosen_plan,\n",
    "    FOREIGN KEY (rhs) REFERENCES opt_chosen_plan,\n",
    "    FOREIGN KEY (order_table, order_column) REFERENCES catalog_columns,\n",
    "    FOREIGN KEY (parent) REFERENCES opt_chosen_plan,\n",
    "    \n",
    "    CHECK (   (level = 1 AND am_id IS NOT NULL AND type IS NOT NULL)\n",
    "           OR (level > 1 AND top_join IS NOT NULL AND lhs IS NOT NULL and rhs IS NOT NULL))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup 2: Populating the Metadata\n",
    "### Create Boating Club database\n",
    "Here we define and populate an instance of the boating club database from the class examples. The actual data tables will be in the `public` schema. Since our `search_path` was set to have `sqlopt` first, we explicitly specify the `public` schema here.\n",
    "\n",
    "This is the first time we embed SQL in Python code. Note the use of the one-line (`%sql`) syntax for `ipython-sql`, and the way we pass Python variable values into SQL queries via the `:` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%sql DROP TABLE IF EXISTS public.sailors CASCADE;\n",
    "%sql DROP TABLE IF EXISTS public.boats CASCADE;\n",
    "%sql DROP TABLE IF EXISTS public.reserves CASCADE;\n",
    "%sql CREATE TABLE public.sailors(sid integer PRIMARY KEY, sname text, rating integer);\n",
    "%sql CREATE TABLE public.boats(bid integer PRIMARY KEY, bname text, color text);\n",
    "%sql CREATE TABLE public.reserves(rid integer PRIMARY KEY, sid integer, bid integer, rdate date, \\\n",
    "                      FOREIGN KEY (sid) REFERENCES sailors,\\\n",
    "                      FOREIGN KEY (bid) REFERENCES boats);\n",
    "%sql CREATE INDEX ON public.reserves(bid);\n",
    "%sql CREATE INDEX ON public.reserves(sid);\n",
    "\n",
    "cwd = os.getcwd()\n",
    "sailor_path = cwd + '/sailors.csv'\n",
    "boat_path = cwd + '/boats.csv'\n",
    "reserve_path = cwd + '/reserves.csv'\n",
    "%sql COPY sailors FROM :sailor_path WITH (FORMAT csv);\n",
    "%sql COPY boats FROM :boat_path WITH (FORMAT csv);\n",
    "%sql COPY reserves FROM :reserve_path WITH (FORMAT csv);   \n",
    "%sql ANALYZE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the metadata: information about the class Boating Club database\n",
    "Here we copy metadata from the PostgreSQL catalog into our own catalog tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "INSERT INTO catalog_tables \n",
    "SELECT table_name, NULL::integer, NULL::integer\n",
    "  FROM information_schema.tables\n",
    " WHERE table_schema = 'public';\n",
    "    \n",
    "INSERT INTO catalog_columns\n",
    "SELECT table_name, ordinal_position, column_name, data_type, NULL::integer\n",
    "  FROM information_schema.columns\n",
    " WHERE table_schema = 'public';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate access methods.\n",
    "Here we populate access methods for our tables:\n",
    "- We assume there is a heap file for each table\n",
    "- We also query PostgreSQL to see what indexes have been created, assuming each index is of type 'btree'. Note that PostgreSQL automatically builds an index on the primary key of a table.\n",
    "This is the first time we use a SQL sequence number generator to autogenerate unique ids. You can read more about SQL sequences [in the PostgreSQL manual](https://www.postgresql.org/docs/current/static/sql-createsequence.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Sequence generator for access method ids\n",
    "DROP SEQUENCE IF EXISTS catalog_am_seq CASCADE;\n",
    "CREATE SEQUENCE catalog_am_seq;\n",
    "\n",
    "INSERT INTO catalog_access_methods\n",
    "SELECT nextval('catalog_am_seq'), table_name, NULL, 'heap'\n",
    "  FROM catalog_tables;\n",
    "    \n",
    "INSERT INTO catalog_access_methods\n",
    "SELECT nextval('catalog_am_seq'), t.relname, a.attnum, 'btree'\n",
    "  FROM\n",
    "    pg_class t,\n",
    "    pg_class i,\n",
    "    pg_index ix,\n",
    "    pg_attribute a,\n",
    "    pg_namespace ns\n",
    " WHERE\n",
    "    t.oid = ix.indrelid\n",
    "    and i.oid = ix.indexrelid\n",
    "    and a.attrelid = t.oid\n",
    "    and a.attnum = ANY(ix.indkey)\n",
    "    and t.relkind = 'r'\n",
    "    and t.relnamespace = ns.oid\n",
    "    and ns.nspname = 'public';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next cell represents a parsed query, stored as a bunch of metadata.\n",
    "Here we populate the query tables with parsed output for the following SQL query:\n",
    "```sql\n",
    "SELECT * \n",
    "  FROM sailors S, reserves R, boats B\n",
    " WHERE S.rating > 5 AND B.bid = 100 AND S.sid = R.sid AND R.bid = B.bid;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "INSERT INTO query_tables VALUES ('sailors'), ('boats'), ('reserves');\n",
    "INSERT INTO query_predicates VALUES \n",
    "    (1, 'sailors', 3, '>', 5, NULL, NULL), (2, 'boats', 1, '=', 100, NULL, NULL), \n",
    "    (4, 'sailors', 1, NULL, NULL, 'reserves', 2), (5, 'reserves', 3, NULL, NULL, 'boats', 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Part 1: Optimizer cost and selectivity formulae\n",
    "Your first challenge is to define the optimizer cost formulae as PostgreSQL user-defined functions (UDFs). These functions should return type `numeric`, and can be implemented as simple SQL expressions that return a single row with a single column.  More information on PostgreSQL UDFs can be found [in the manual](https://www.postgresql.org/docs/current/static/xfunc-sql.html).\n",
    "\n",
    "For simplicity we will not distinguish clustered and unclustered indexes; assume the cost of an index scan is the unclustered cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP FUNCTION IF EXISTS SeqScanCost(integer, integer) CASCADE;\n",
    "DROP FUNCTION IF EXISTS IndexScanCost(integer, integer);\n",
    "DROP FUNCTION IF EXISTS HashJoinCost(integer, integer, integer, integer, integer);\n",
    "DROP FUNCTION IF EXISTS SortMergeJoinCost(integer, integer, integer, integer, integer);\n",
    "DROP FUNCTION IF EXISTS BNLJCost(integer, integer, integer, integer, integer);\n",
    "DROP FUNCTION IF EXISTS INLJCost(integer, integer, integer, integer, integer, integer);\n",
    "DROP FUNCTION IF EXISTS SingleColumnSelectivity(char(2), integer, integer, integer);\n",
    "DROP FUNCTION IF EXISTS TwoColumnEqSelectivity(integer, integer);\n",
    "\n",
    "--\n",
    "-- Scans\n",
    "--\n",
    "CREATE FUNCTION SeqScanCost(npages integer, ntups integer) RETURNS numeric AS $$\n",
    "  -- WE ARE GIVING YOU THIS ONE FOR FREE :-)\n",
    "  SELECT (npages + H.cpufactor*ntups)::numeric\n",
    "    FROM system_hardware H\n",
    "   LIMIT 1\n",
    "$$ LANGUAGE SQL;\n",
    "\n",
    "-- Unclustered cost only for now\n",
    "CREATE FUNCTION IndexScanCost(npages integer, ntups integer) \n",
    "RETURNS numeric AS $$\n",
    "    -- YOUR CODE HERE\n",
    "$$ LANGUAGE SQL;\n",
    "\n",
    "\n",
    "--\n",
    "-- Joins\n",
    "-- \n",
    "CREATE FUNCTION HashJoinCost(qbufs integer, lhspages integer, lhstups integer, \n",
    "                         rhspages integer, rhstups integer) RETURNS numeric AS $$\n",
    "    -- YOUR CODE HERE\n",
    "$$ LANGUAGE SQL;\n",
    "\n",
    "CREATE FUNCTION SortMergeJoinCost(qbufs integer, lhspages integer, lhstups integer, \n",
    "                         rhspages integer, rhstups integer) RETURNS numeric AS $$\n",
    "    -- YOUR CODE HERE\n",
    "$$ LANGUAGE SQL;\n",
    "\n",
    "DROP FUNCTION IF EXISTS BNLJCost(integer, integer, integer, integer, integer);\n",
    "CREATE FUNCTION BNLJCost(qbufs integer, lhspages integer, lhstups integer, \n",
    "                         rhspages integer, rhstups integer) RETURNS numeric AS $$\n",
    "    -- YOUR CODE HERE\n",
    "$$ LANGUAGE SQL;\n",
    "\n",
    "CREATE FUNCTION INLJCost(qbufs integer, lhspages integer, lhstups integer, \n",
    "                         rhspages integer, rhstups integer, rhs_numvals integer) \n",
    "                RETURNS numeric AS $$\n",
    "    -- YOUR CODE HERE\n",
    "$$ LANGUAGE SQL;\n",
    "\n",
    "\n",
    "--\n",
    "-- SingleColumnSelectivity\n",
    "--\n",
    "CREATE FUNCTION SingleColumnSelectivity(op char(2), constant integer, bin_lo integer, bin_hi integer) \n",
    "        RETURNS numeric AS $$\n",
    "    -- YOUR CODE HERE\n",
    "$$ LANGUAGE SQL;\n",
    "\n",
    "--\n",
    "-- TwoColumnEqSelectivity\n",
    "--\n",
    "CREATE FUNCTION TwoColumnEqSelectivity(lhs_height integer, rhs_height integer)\n",
    "       RETURNS numeric AS $$\n",
    "    -- YOUR CODE HERE\n",
    "$$ LANGUAGE SQL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Part 2: Populate the Optimizer Statistics\n",
    "You are responsible to write queries to gather the statistics about tables and columns. \n",
    "\n",
    "This involves two basic tasks:\n",
    "- Get the number of tuples and pages for each table. Assume that each page holds 4KB. Assume that integers are 4 bytes long, floats and dates are 8 bytes long, and strings are as many bytes as their length.\n",
    "- gather distinct values, min and max (1-bucket histogram) for each integer column. For non-integer columns, min and max are set to NULL\n",
    "\n",
    "Note that you'll have to run a query over each table to compute `ntups` and `npages`, and over each column of each table to compute `num_vals`, `lo` and `hi`. This is not possible in SQL, since SQL does not allow variables in the `FROM` clause. (That would be [second-order logic](https://en.wikipedia.org/wiki/Second-order_logic)). To achieve this you will have to embed SQL in Python, and pass Python variable values into your SQL. Be careful with your use of `$` vs. `:` in `ipython-sql`!\n",
    "\n",
    "We've given you the SQL code to look up npages in the PostgreSQL catalog; you need to write the SQL code to compute `ntups`, and the column statistics. You should *not* take the statistics from the PostgreSQL catalog, you should compute them directly from the user tables. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablenames = %sql select table_name from catalog_tables;\n",
    "for t in tablenames:\n",
    "    tname = t[0]\n",
    "    %sql UPDATE catalog_tables \\\n",
    "            SET npages = (SELECT relpages \\\n",
    "                            FROM pg_class r, pg_namespace ns \\\n",
    "                           WHERE r.relnamespace = ns.oid \\\n",
    "                             AND r.relname = :tname \\\n",
    "                             AND ns.nspname = 'public') \\\n",
    "          WHERE table_name = :tname;\n",
    "\n",
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Part 3: Dynamic Programming\n",
    "Now that we have all our state set up, we can implement the core algorithm in SQL. \n",
    "\n",
    "First you will want to define your dynamic programming table and any ancillary tables or views you want to keep the state of the algorithm.\n",
    "\n",
    "Hint: you may want to use the `CREATE SEQUENCE` feature to generate unique IDs for subplans found (and later reused) during dynamic programming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Your DDL statements go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can write the DML queries for the dynamic program. Take it in two parts: base case and inductive case.\n",
    "\n",
    "### Base case: find best single-table access plans\n",
    "Here you need to write SQL to populate the dynamic programming table with level-1 information on scan subplans--both heap scans and index scans. We'll consider every heap scan, and any indexscan where the index key matches a column referenced in the query predicates.\n",
    "\n",
    "We have given you a set of view skeletons to break the problem into pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "-- Extract all table_name references in predicates that could benefit from an index. \n",
    "-- There are two types of predicates:\n",
    "-- 1) For predicates involving only one table, we want to know the \n",
    "--    table, column_id, selection operator and the constant.\n",
    "-- 2) For predicates representing joins, we want to know tables \n",
    "--    and column_ids, as well as the join operator. Note that we're interested\n",
    "--    in indexes both for the rhs and lhs of the predicate!\n",
    "DROP VIEW IF EXISTS opt_index_refs CASCADE;\n",
    "CREATE VIEW opt_index_refs(table_name, column_id, operator, constant) AS (\n",
    "    -- YOUR CODE GOES HERE\n",
    ");\n",
    "\n",
    "-- Now combine the results of the previous view with rows that capture the case of \n",
    "-- heap scans that do not match a predicate.\n",
    "-- Same schema as the previous view, but heap scans will have NULL info for \n",
    "-- columns, operators, and constants.\n",
    "DROP VIEW IF EXISTS opt_table_col_refs CASCADE;\n",
    "CREATE VIEW opt_table_col_refs(table_name, column_id, operator, constant) AS (\n",
    "    -- YOUR CODE GOES HERE\n",
    ");\n",
    "\n",
    "-- Now find all the access methods corresponding to the references in the previous view.\n",
    "DROP VIEW IF EXISTS opt_scan_access_methods CASCADE;\n",
    "CREATE VIEW opt_scan_access_methods(table_name, column_id, am_id, type, npages, ntups, \n",
    "                                    order_column, operator, constant) AS (\n",
    "    -- YOUR CODE GOES HERE\n",
    ");\n",
    "\n",
    "-- Compute costs for all full-scan access methods:\n",
    "-- these are scans that return every tuple in the table. We should consider both \n",
    "-- heap and index access methods, as both types can return all tuples. The index\n",
    "-- scans will produce interesting orders based on their search key.\n",
    "DROP VIEW IF EXISTS opt_scan_AM_costs;\n",
    "CREATE VIEW opt_scan_AM_costs(table_name, column_id, am_id, type, cost, npages, ntups, \n",
    "                              order_table, order_column, operator, constant) AS (\n",
    "    -- YOUR CODE GOES HERE\n",
    ");\n",
    "\n",
    "-- Compute costs for index access methods that match a query predicate.\n",
    "-- Cost formulas for indexes need to take predicate selectivity into account, \n",
    "-- since they only scan a fraction of the index and heap file. Again, these\n",
    "-- return interesting orders.\n",
    "DROP VIEW IF EXISTS opt_index_AM_costs CASCADE;\n",
    "CREATE VIEW opt_index_AM_costs(table_name, column_id, am_id, type, cost, npages, ntups,\n",
    "                               order_table, order_column) AS (\n",
    "    -- YOUR CODE GOES HERE\n",
    ");\n",
    "\n",
    "-- Combine all of the level-1 access methods and their cost estimates\n",
    "-- in a single view.\n",
    "DROP VIEW IF EXISTS opt_all_scan_access_methods CASCADE;\n",
    "CREATE VIEW opt_all_scan_access_methods(table_name, am_id, type, cost, npages, ntups,\n",
    "                                        order_table, order_column) AS (\n",
    "    -- YOUR CODE GOES HERE\n",
    ");\n",
    "\n",
    "-- Assign a unique ID to each AM.\n",
    "-- We materialize this table_name so that each access method (subplan)\n",
    "-- is assigned a persistent unique ID from a SQL sequence generator.\n",
    "DROP TABLE IF EXISTS opt_numbered_scan_AMs CASCADE;\n",
    "CREATE TABLE opt_numbered_scan_AMs(pid, table_name, am_id, type, cost, npages, ntups,\n",
    "                                   order_table, order_column) AS (\n",
    "    -- YOUR CODE GOES HERE\n",
    ");\n",
    "\n",
    "-- Find the minimum-cost plan for each interesting order (including NULL). You\n",
    "-- will need to use an \"argmin\" style query pattern (see HW1).\n",
    "-- Insert the results (with pids) into opt_bestplans, with level = 1\n",
    "\n",
    "INSERT INTO opt_bestplans \n",
    "    -- YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inductive Case: form recursively larger join trees\n",
    "In this cell we consider all ways of joining the n-1-way joins with the level-1 scans. Be sure to keep plans for all interesting orders! (Note that we are not handling GROUP BY or ORDER BY in this homework, so the only interesting orders related to joins.)\n",
    "\n",
    "For each plan you consider, you need to compute cost, and use selectivity estimates to compute the output npages and ntups. You also need to track the output ordering based on the input. Currently we only track one column as an interesting order; for sort-merge join you can pick either of the join columns.\n",
    "\n",
    "Make sure you consider \"commuting\" the join predicates: i.e. if you have a predicate of the form `R.x = S.y` you should also consider plans in which `R.x` is the right child of a join.\n",
    "\n",
    "You can implement the induction by looping over values of n in Python, or by using a SQL [`WITH RECURSIVE`](https://www.postgresql.org/docs/9.6/static/queries-with.html) query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we're done with iteration to find best join trees, let's choose the 1 best plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Pick the root of the cheapest plan. If there are ties on cost, break arbitrarily\n",
    "DROP VIEW IF EXISTS opt_final;\n",
    "CREATE VIEW opt_final AS\n",
    "-- YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now given the root of the cheapest plan, construct the full plan tree with its\n",
    "parent-child relationships, and sibling orders.  Start from the root and work downward.\n",
    "\n",
    "This can be done with a single, relatively simple [`WITH RECURSIVE`](https://www.postgresql.org/docs/9.6/static/queries-with.html) query, or you can use a Python loop \n",
    "to issue multiple queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- YOUR CODE GOES HERE\n",
    "\n",
    "SELECT * FROM opt_chosen_plan;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the best plan is stored in `opt_best_plan`, and the database system can compile it into iterator objects to execute. You can use the [visualizer notebook](visualizer.ipynb) to see a graphical version of the plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
